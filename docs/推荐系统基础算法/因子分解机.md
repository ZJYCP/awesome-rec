# 因子分解机

---

> 因子分解机(Factorization Machine, FM)，该算法的核心思路来自矩阵分解。分解机自2010年被提出后，由于易于整合交叉特征，可以处理高维稀疏数据，在推荐系统以及CTR等领域得到大规模使用。



## 分解机的简单介绍

分解机最早有Steffen Rendle于2010年在ICDM上提出，即时在数据非常稀疏的情况下，依然能够估计出可靠的参数。

常用的简单模型由线性回归模型和逻辑回归模型。线性模型要求特征之间想相互独立的，因为它无法拟合特征之间的非线性关系。LR模型则需要人工进行特征工程，耗时耗力。

### POLY2模型

**POLY2模型，特征交叉的开始**。对任何两个特征时间进行了两两交叉。
$$
\hat{y}(x) = w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^{n-1}\sum_{j=i+1}^nw_{ij}x_ix_j
$$
需要估计的参数：$w_0, w_i, w_{ij}$

POLY2模型存在两个较大的缺陷：

1. 在特征向量极度稀疏的情况下，大部分交叉特征的权重由于缺乏有效的数据而难以进行训练。对于广告、推荐场景来说，数据是很稀疏的，因此上面这种整合二阶两两交叉特征的模型并没有在工业界得到广泛采用。
2. 权重参数有$n$到$n^2$，增大了训练复杂度。

### 分解机

分解机对上述的二阶交叉特征的系数进行了调整，让系数不再是独立无关的，从而减少模型独立系数的数量，进而解决了由于数据的稀疏问题导致无法训练处参数的问题。
$$
\hat{y}(x) = w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^{n-1}\sum_{j=i+1}^n<v_i,v_j>x_ix_j
$$
需要估计的参数：$w_0,(w_1,w_2...w_n),V\in \mathbb{R}^{n\times k}$

$v_i,v_j$是底维向量，类似于矩阵分解中的用户或者标的物的特征向量表示，$<>$表示两个向量的内积操作。k的取值一般较小，100左右。
$$
<v_i,v_j>=\sum_{f=1}^kv_{i,f}v_{j,f}
$$




## 分解机参数预估与模型价值

### 分解机在稀疏场景下的参数估计

分解机中一个交叉项的数据可以辅助用来训练另一个交叉项，只要两者有相同的一个变量

分解机模型通过将二阶交叉特征系数做分解，让二阶交叉项的系数不再独立，因此系数的数量是要远小于POLO2的。分解机的系数个数为1+n+kn,是n的线性函数

### 分解机的计算复杂度

分解机的计算时间复杂度是O(kn)，更准确的讲时间复杂度是$O(km_d)$,$m_D$是训练样本中平均非零的特征个数。

具体推导如下：

![image-20220717132807261](https://blog-1252832257.cos.ap-shanghai.myqcloud.com/image-20220717132807261.png)



### 分解机模型求解

TODO



### 模型预测

1. 回归问题

   $\hat{y}(x)$直接作为预测项

2. 二元分类问题

   $Sgn(\hat{y}(x))$作为最终的分类，可以通过hinge损失或者logit损失来训练二元分类问题

3. 排序问题

## 分解机与其他模型的关系

TODO

### FM与矩阵分解的关系



### FM与SVM的关系



## 分解机的工程实现

Rendle开源了一个求解FM的高效C++库：libFM，实现了通过SGD、ALS、MCMC三种方法来训练FM模型。

TODO

## 分解机的扩展

### 高阶分解机

高阶分解机将交叉项扩展到最多d（d>2)个特征上
$$
\hat{y}(x):=w_0+\sum_{i=1}^nw_ix_i+\sum_{l=2}^d\sum_{i_1=1}^n...\sum_{i_l=i_{l-1}-1}^n(\prod_{j=1}^lx_{i_j})(\sum_{f=1}^{k_l}\prod_{j=1}^lv_{i_f,f}^{(l)})
$$

> *Blondel M, Fujino A, Ueda N, et al. Higher-order factorization machines[J]. Advances in Neural Information Processing Systems, 2016, 29.* 对高阶分解机做出了深入的介绍

### FFM

Field-aware Factorization Machines

| **Clicked?** | Country | Day      | Ad_type |
| :----------- | :------ | :------- | :------ |
| **1**        | USA     | 26/11/15 | Movie   |
| **0**        | China   | 1/7/14   | Game    |
| **1**        | China   | 19/2/15  | Game    |

“Clicked?“是label，Country、Day、Ad_type是特征。由于三种特征都是categorical类型的，需要经过独热编码（One-Hot Encoding）转换成数值型特征。

| **Clicked?** | Country=USA | Country=China | Day=26/11/15 | Day=1/7/14 | Day=19/2/15 | Ad_type=Movie | Ad_type=Game |
| :----------- | :---------- | :------------ | :----------- | :--------- | :---------- | :------------ | :----------- |
| **1**        | 1           | 0             | 1            | 0          | 0           | 1             | 0            |
| **0**        | 0           | 1             | 0            | 1          | 0           | 0             | 1            |
| **1**        | 0           | 1             | 0            | 0          | 1           | 0             | 1            |



Field的概念: 域代表特征域，域内的特征一般是采用one-hot编码形成的一段one-hot特征向量如“Day=26/11/15”、“Day=1/7/14”、“Day=19/2/15”这三个特征都是代表日期的，可以放到同一个field中。

FFM的模型公式如下：
$$
\hat{y}(x) = w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^{n-1}\sum_{j=i+1}^n<v_{(i,f_j)},v_{(j,f_i)}>x_ix_j
$$
在FM中，每一个特征的对应的隐向量都是固定的，对应的是一个向量。而FFM中每个特征对应的是一组向量，在进行特征交叉时，选择与另一个特征所在域对应的隐向量。

在FFM，对每一个特征$x_i$，每一个field$f_j$，学习一个$k$维的隐向量$v_{i,f_j}$,学习参数数量为$n\times f \times k$。并且$f$的大小和特征数时相关的，因此复杂度为$kn^2$

开源实现：https://github.com/aksnzhy/xlearn

### DeepFM

本节内容在——介绍。TODO

## 近实时分解机

Google在2013年提出了FTRL（Follow-The-Regularized-Leader）算法，可以高效地在线训练LR模型，基于其思路，可以对FM离线性训练算法进行改造，让FM具备在线学习的能力。

相关机器学习平台也是具有FM算法的FTRL实现的。

> 相关文献
>
> *Ta A P. Factorization machines with follow-the-regularized-leader for CTR prediction in display advertising[C]//2015 IEEE International Conference on Big Data (Big Data). IEEE, 2015: 2889-2891.*
>
> *Luo L, Zhang W, Zhang Z, et al. Sketched follow-the-regularized-leader for online factorization machine[C]//Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2018: 1900-1909.*
>
> *Lin X, Zhang W, Zhang M, et al. Online compact convexified factorization machine[C]//Proceedings of the 2018 World Wide Web Conference. 2018: 1633-1642.*

## 分解机在推荐系统上的应用

当预测用户对标的物评分的时候，就是回归问题；当预测用户是否点击标的物时，就可以看做分类问题，通过增加logit变化实现。

构建FM模型的特征主要分为如下4类：

1. 用户与标的物的交互行为信息
2. 用户相关信息
3. 标的物相关信息
4. 上下文信息

## 分解机的优势

1. 可以整合特征交叉，效果不错
2. 线性时间复杂度
3. 可以应对稀疏数据的情况
4. 模型相对简单，便于工程实现



